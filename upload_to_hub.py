#!/usr/bin/env python3
"""
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘       AI4BHARAT TUNE-ATHON  â€”  UPLOAD TO HUB  v1.0                  â•‘
â•‘                                                                       â•‘
â•‘  Run this AFTER finetune.py has finished training.                   â•‘
â•‘  Team Member 2 sets their own credentials in upload.env              â•‘
â•‘  and uploads the trained adapter to their own HuggingFace Hub.       â•‘
â•‘                                                                       â•‘
â•‘  SETUP:                                                               â•‘
â•‘    cp upload.env.example upload.env                                  â•‘
â•‘    # Edit upload.env with YOUR credentials                           â•‘
â•‘                                                                       â•‘
â•‘  USAGE:                                                               â•‘
â•‘                                                                       â•‘
â•‘  Option A â€” Push adapter only (fast, ~1 min):                        â•‘
â•‘    python upload_to_hub.py --adapter-only                             â•‘
â•‘                                                                       â•‘
â•‘  Option B â€” Merge LoRA into full model, then push (recommended):     â•‘
â•‘    python upload_to_hub.py                                            â•‘
â•‘                                                                       â•‘
â•‘  Option C â€” Push from a custom adapter path:                         â•‘
â•‘    python upload_to_hub.py --adapter-path /path/to/adapters/Kerala   â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

WHAT THIS DOES:
  1. Reads YOUR credentials from upload.env (separate from finetune.env)
  2. Loads the trained LoRA adapter from adapters/{STATE}/
  3. Merges it into the Qwen3-1.7B base model (full FP16)
  4. Uploads the merged model to YOUR HuggingFace Hub repo
  5. If merge fails: falls back to pushing the adapter only

WHAT YOU NEED ON THIS MACHINE:
  - adapters/{STATE}/  folder (copied from the training machine, or
    directly available if running on the same machine after training)
  - unsloth-mlx installed  (same setup as finetune.py)
  - YOUR HuggingFace WRITE token in upload.env
"""

import os, sys, shutil, argparse
from pathlib import Path

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# LOAD upload.env  (separate from the training .env)
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
try:
    from dotenv import load_dotenv
    # Prefer upload.env â€” falls back to .env if upload.env doesn't exist
    if Path("upload.env").exists():
        load_dotenv("upload.env")
        print("ğŸ“„  Loaded credentials from upload.env")
    else:
        load_dotenv()
        print("ğŸ“„  upload.env not found â€” loaded from .env")
except ImportError:
    pass  # env vars must be set manually

from huggingface_hub import login, HfApi

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# CONFIG  (all from upload.env)
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def _require(key):
    v = os.getenv(key, "").strip()
    if not v:
        print(f"\nâŒ  Missing required variable: {key}")
        print(f"    Add it to upload.env:  {key}=<value>\n")
        sys.exit(1)
    return v

def _optional(key, default):
    return os.getenv(key, default).strip() or default

HF_TOKEN     = _require("HF_TOKEN")
HF_USERNAME  = _require("HF_USERNAME")
STATE        = _require("STATE")
PROJECT_NAME = _optional("PROJECT_NAME", "AI4Bharat-State-Expert")

# The base model that was used for training â€” must match finetune.py
BASE_MODEL   = "mlx-community/Qwen3-1.7B-4bit"
MAX_SEQ      = 2048

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# PATHS  (must match finetune.py layout)
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
DEFAULT_ADAPT_DIR = Path(f"adapters/{STATE}")
MERGE_DIR         = Path(f"merged_upload/{STATE}")   # separate from training merge dir

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# HELPERS
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def verify_adapter(adapter_path: Path):
    """Check that the adapter directory has the expected files."""
    required = ["adapters.safetensors", "adapter_config.json"]
    missing  = [f for f in required if not (adapter_path / f).exists()]

    # Some versions save directly in the dir, others in an 'adapters/' subdir
    subdir = adapter_path / "adapters"
    if missing and subdir.exists():
        missing = [f for f in required if not (subdir / f).exists()]
        if not missing:
            return subdir   # return the actual location

    if missing:
        print(f"\nâŒ  Adapter directory incomplete: {adapter_path}")
        print(f"    Missing files: {missing}")
        print(f"    Make sure training completed successfully and")
        print(f"    the adapters/ folder is on this machine.")
        sys.exit(1)

    return adapter_path

def push_adapter_only(adapter_path: Path, repo_id: str):
    """Push raw LoRA adapter files to Hub. Fast (~1 min)."""
    print(f"\nğŸ“¤  Pushing LoRA adapter files â†’ {repo_id}")
    print(f"    From: {adapter_path}/")
    try:
        api = HfApi()
        api.upload_folder(
            folder_path = str(adapter_path),
            repo_id     = repo_id,
            repo_type   = "model",
            token       = HF_TOKEN,
        )
        print(f"    âœ…  Adapter live: https://huggingface.co/{repo_id}")
        print(f"\n    â„¹ï¸   To use this adapter:")
        print(f"         from peft import PeftModel")
        print(f"         from transformers import AutoModelForCausalLM")
        print(f"         base = AutoModelForCausalLM.from_pretrained('Qwen/Qwen3-1.7B')")
        print(f"         model = PeftModel.from_pretrained(base, '{repo_id}')")
        return True
    except Exception as e:
        print(f"    âŒ  Upload failed: {e}")
        return False

def merge_and_push(adapter_path: Path, repo_id: str):
    """
    Load base model + adapter, merge weights into full FP16 model, push.
    This produces a standalone model â€” no PEFT library needed to run it.
    Takes ~10-20 min depending on upload speed.
    """
    from unsloth_mlx import FastLanguageModel

    print(f"\nğŸ“¥  Loading base model: {BASE_MODEL}")
    model, tok = FastLanguageModel.from_pretrained(
        model_name     = BASE_MODEL,
        max_seq_length = MAX_SEQ,
        load_in_4bit   = True,
    )

    print(f"ğŸ”Œ  Loading LoRA adapter from: {adapter_path}/")
    model.load_adapter(str(adapter_path))

    # Merge LoRA weights permanently into base model
    MERGE_DIR.mkdir(parents=True, exist_ok=True)
    print(f"\nğŸ”€  Merging LoRA â†’ FP16 (this takes a few minutes)...")
    try:
        model.save_pretrained_merged(
            str(MERGE_DIR), tok, save_method="merged_16bit"
        )
        print(f"    âœ…  Merged model saved â†’ {MERGE_DIR}/")
    except Exception as e:
        print(f"    âŒ  Merge failed: {e}")
        print(f"    Falling back to adapter-only upload...")
        shutil.rmtree(str(MERGE_DIR), ignore_errors=True)
        return False

    # Upload merged model
    print(f"\nğŸ“¤  Uploading merged model â†’ {repo_id}")
    try:
        api = HfApi()
        api.upload_folder(
            folder_path = str(MERGE_DIR),
            repo_id     = repo_id,
            repo_type   = "model",
            token       = HF_TOKEN,
        )
        print(f"    ğŸ‰  Full model live: https://huggingface.co/{repo_id}")
        # Clean up local merged dir to save disk space
        shutil.rmtree(str(MERGE_DIR), ignore_errors=True)
        print(f"    ğŸ§¹  Cleaned up local merged dir")
        return True
    except Exception as e:
        print(f"    âŒ  Upload failed: {e}")
        print(f"    Merged model is still saved at {MERGE_DIR}/")
        print(f"    You can retry the upload manually:")
        print(f"      huggingface-cli upload {repo_id} {MERGE_DIR}/ --repo-type model")
        return False

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# MAIN
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def main():
    parser = argparse.ArgumentParser(
        description="AI4Bharat Tune-Athon: Upload trained model to HuggingFace Hub",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
examples:
  python upload_to_hub.py                             # merge + push full model
  python upload_to_hub.py --adapter-only              # push adapter only (fast)
  python upload_to_hub.py --adapter-path adapters/Kerala  # custom adapter path
        """,
    )
    parser.add_argument(
        "--adapter-only",
        action="store_true",
        help="Push raw LoRA adapter files only (fast, ~1 min). "
             "Recipient needs PEFT to use it.",
    )
    parser.add_argument(
        "--adapter-path",
        type=str,
        default=None,
        help=f"Path to adapter directory (default: adapters/{STATE})",
    )
    args = parser.parse_args()

    # Resolve adapter path
    adapter_path = Path(args.adapter_path) if args.adapter_path else DEFAULT_ADAPT_DIR

    # Banner
    print(f"\n{'â•'*64}")
    print(f"  ğŸ“¤  AI4Bharat Tune-Athon  â€”  Upload to Hub")
    print(f"{'â”€'*64}")
    print(f"  State        : {STATE}")
    print(f"  Adapter path : {adapter_path}/")
    repo_id = f"{HF_USERNAME}/{PROJECT_NAME}-{STATE}"
    print(f"  Destination  : https://huggingface.co/{repo_id}")
    print(f"  Mode         : {'Adapter only' if args.adapter_only else 'Merge + full model'}")
    print(f"{'â•'*64}")

    # Verify adapter exists and is complete
    adapter_path = verify_adapter(adapter_path)

    # Authenticate
    print(f"\nğŸ”  Authenticating as {HF_USERNAME}...")
    login(token=HF_TOKEN)
    print(f"    âœ…  Authenticated")

    # Create repo if it doesn't exist
    api = HfApi()
    try:
        api.create_repo(
            repo_id   = repo_id,
            repo_type = "model",
            token     = HF_TOKEN,
            exist_ok  = True,   # no error if already exists
        )
    except Exception as e:
        print(f"    âš ï¸   Could not create repo (may already exist): {e}")

    # Upload
    if args.adapter_only:
        success = push_adapter_only(adapter_path, repo_id)
    else:
        success = merge_and_push(adapter_path, repo_id)
        if not success:
            print(f"\nâ†©ï¸   Retrying with adapter-only upload...")
            success = push_adapter_only(adapter_path, repo_id)

    # Final status
    print(f"\n{'â•'*64}")
    if success:
        print(f"  ğŸ  Upload complete!")
        print(f"  ğŸ”—  https://huggingface.co/{repo_id}")
    else:
        print(f"  âŒ  Upload failed. Adapter is safe locally at {adapter_path}/")
        print(f"      Check your HF_TOKEN has WRITE access and try again.")
    print(f"{'â•'*64}\n")

if __name__ == "__main__":
    main()
